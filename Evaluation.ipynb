{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7abea0ad",
   "metadata": {},
   "source": [
    "Before you turn this problem in, make sure everything runs as expected. First, **restart the kernel** (in the menubar, select Kernel$\\rightarrow$Restart) and then **run all cells** (in the menubar, select Cell$\\rightarrow$Run All) to avoid typical problems with Jupyter notebooks. **Unfortunately, this does not work with Chrome right now, you will also need to reload the tab in Chrome afterwards**.\n",
    "\n",
    "Make sure you fill in any place that says `YOUR CODE HERE` or \"YOUR ANSWER HERE\". Please put your name here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "id": "07e42b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME = \"AVISHA BHIRYANI\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74c3d3fb",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "961a06b0",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4092c0667039a312554e2a9654f525e8",
     "grade": false,
     "grade_id": "cell-000d65f4ae6fc8c2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Evaluation\n",
    "\n",
    "In this (shorter) assignment, we want to compare the quality of different clustering approaches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "id": "084b86b5",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ad68a00526ce7ac18a099b727b1d2521",
     "grade": false,
     "grade_id": "cell-d44b13e9602b47dd",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np, pandas as pd, scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "id": "b9ea4fee",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "10e3ff83895cad9f4d12f0294405f135",
     "grade": false,
     "grade_id": "cell-5943456df56d540b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Load the input data\n",
    "import json, gzip\n",
    "raw = json.load(gzip.open(\"/data/simpsonswiki.json.gz\", \"rt\", encoding=\"utf-8\"))\n",
    "titles, texts, classes = [x[\"title\"] for x in raw], [x[\"text\"] for x in raw], [x[\"c\"] for x in raw]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a8485ef",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6fa0809fd05f7eb0abfd47d3a574c757",
     "grade": false,
     "grade_id": "cell-358845eb04cc6a40",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "This is a minimal example implementation of spherical k-means, which we will use in the following."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "id": "535ba240",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3e1806a1463bf286e081e222d226e1d0",
     "grade": false,
     "grade_id": "cell-a2650dba6199cf26",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Vectorize the text for k-means (minimalistic)\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vect = TfidfVectorizer(stop_words=\"english\", sublinear_tf=True, smooth_idf=False, min_df=5)\n",
    "vect.fit(texts)\n",
    "vect.idf_ -= 1\n",
    "tfidf, idf = vect.transform(texts), vect.idf_\n",
    "vocabulary = vect.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "id": "0ae62865",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "265d4bad3376697ff65fecf669834d8a",
     "grade": false,
     "grade_id": "cell-d7b358e908353de3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Minimalistic implementation for spherical k-means, so we use the same version in this assignment\n",
    "# This is NOT meant as an example of good code, but to be snort.\n",
    "def initial_centers(tfidf, k, seed):\n",
    "    return tfidf[np.random.default_rng(seed=seed).choice(tfidf.shape[0], k, replace=False)]\n",
    "\n",
    "def sphericalkmeans(tfidf, centers, max_iter=100):\n",
    "    \"\"\"REQUIRES the input to be L2 normalized, and does not handle corner cases such as empty clusters!\"\"\"\n",
    "    last_assignment = None\n",
    "    for iter in range(max_iter):\n",
    "        assignment = np.asarray((tfidf @ centers.T).argmax(axis=1)).squeeze()\n",
    "        if last_assignment is not None and all(assignment == last_assignment): break\n",
    "        last_assignment, centers = assignment, np.zeros(centers.shape)\n",
    "        for i in range(centers.shape[0]):\n",
    "            c = tfidf[assignment == i,:].sum(axis=0).A1\n",
    "            centers[i] = c / np.sqrt((c**2).sum())\n",
    "    return centers, assignment, iter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bcdcd00",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c0a91db05eec6cb4b6bde40033a4c5c3",
     "grade": false,
     "grade_id": "cell-8280cd698d60e826",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Implement a function to compute a cross-tabulation matrix\n",
    "\n",
    "Compute the cross-tabulation matrix compares every class to every cluster. Append an additional row and column for the cluster sizes / class totals and the dataset size. Make sure to accept clusters that are, e.g., labeled using text labels and *not* just as integers 0..k.\n",
    "\n",
    "Write your own code, do not use `pandas.crosstab`.\n",
    "\n",
    "You do not need to vectorize this, but try to use numpy operations where easily possible - in particular if you end up waiting a lot for results below!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "id": "23a0a3bc",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d8b7b2692c5b2cb0932a4f1cd9c807a7",
     "grade": false,
     "grade_id": "cell-4c6afb9d1a4a9bb0",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "def cross_tabulation(clu, cla):\n",
    "    \"\"\"Compute the cross-tabulation matrix to compare assignments `clu` and `cla`.\"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    clusters = list(set(clu))\n",
    "    classes = list(set(cla))\n",
    "    \n",
    "    classes_dict = {}\n",
    "    i = 0\n",
    "    for class_val in classes:\n",
    "        classes_dict[class_val] = i\n",
    "        i = i +1\n",
    "        \n",
    "    classes_transformed = [classes_dict.get(x) for x in cla]\n",
    "\n",
    "    cross_tab = np.full((len(clusters)+1,len(classes)+1), int(0))\n",
    "    dict_cluster_points = {}\n",
    "    \n",
    "    for i in clusters:\n",
    "        dict_cluster_points[i] = np.flatnonzero((clu == i))\n",
    "        class_mapping = np.array(classes_transformed)[dict_cluster_points[i].astype(int)]\n",
    "        cluster_class_count = dict(Counter(class_mapping))\n",
    "\n",
    "        for key, value in cluster_class_count.items():\n",
    "            cross_tab[i,int(key)] = int(value)\n",
    "    \n",
    "    cross_tab[-1] = np.sum(cross_tab, axis=0)\n",
    "    cross_tab[:, -1] = np.sum(cross_tab, axis=1)\n",
    "    \n",
    "    return cross_tab "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "id": "06e216ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, _tmp, _ = sphericalkmeans(tfidf, tfidf[:5], 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "id": "128411a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  435,   277,    74,   671,  2657,   220,   870,    33,   516,\n",
       "         5753],\n",
       "       [  141,    88,     9,   132,   726,    24,   293,     8,   212,\n",
       "         1633],\n",
       "       [   64,    35,     3,   176,   474,     4,   252,     4,   168,\n",
       "         1180],\n",
       "       [   44,    18,     1,    44,   346,     5,   125,     3,    59,\n",
       "          645],\n",
       "       [   45,    47,     7,    70,   367,    19,   230,     5,   125,\n",
       "          915],\n",
       "       [  729,   465,    94,  1093,  4570,   272,  1770,    53,  1080,\n",
       "        10126]])"
      ]
     },
     "execution_count": 480,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_tabulation(_tmp, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "id": "d5f0f2e9",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "780d2e0cdf21782c006c5f50e2a98f4c",
     "grade": true,
     "grade_id": "cell-b1c59f6484e29d3a",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "### Automatic tests\n",
    "_, _tmp, _ = sphericalkmeans(tfidf, tfidf[:5], 1)\n",
    "_tmp2 = cross_tabulation(_tmp, np.ones(tfidf.shape[0]))\n",
    "assert isinstance(_tmp2, np.ndarray), \"Must be an array\"\n",
    "assert np.issubdtype(_tmp2.dtype, np.integer), \"Must be an integer array\"\n",
    "if _tmp2.shape == (2,6): print(\"Use first parameter as first index.\")\n",
    "assert _tmp2.shape == (6,2), \"Wrong shape\"\n",
    "assert _tmp2[:-1,:-1].sum() == tfidf.shape[0], \"Not all elements\"\n",
    "assert (_tmp2[:,:-1].sum(axis=1) == _tmp2[:,-1]).all(), \"Sizes are bad\"\n",
    "assert (_tmp2[:-1].sum(axis=0) == _tmp2[-1]).all(), \"Sizes are bad\"\n",
    "assert _tmp2.sum() == 4 * tfidf.shape[0], \"Not all elements\"\n",
    "from unittest.mock import patch\n",
    "with patch('pandas.crosstab', side_effect=Exception(\"Do not use pandas.crosstab\")) as mock_p:\n",
    "    _tmp2 = cross_tabulation(_tmp, _tmp)\n",
    "assert _tmp2.shape == (6,6), \"Wrong shape\"\n",
    "assert _tmp2.sum() == 4 * tfidf.shape[0], \"Not all elements\"\n",
    "assert (_tmp2[:,:-1].sum(axis=1) == _tmp2[:,-1]).all(), \"Sizes are bad\"\n",
    "assert (_tmp2[:-1].sum(axis=0) == _tmp2[-1]).all(), \"Sizes are bad\"\n",
    "del _tmp, _tmp2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "id": "b4890f48",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c083b96cafb44bea6d7a48fbfeba3d44",
     "grade": true,
     "grade_id": "cell-613e1eceee134b0f",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "### Automatic tests\n",
    "_, _tmp, _ = sphericalkmeans(tfidf, tfidf[:5], 1)\n",
    "try:\n",
    "    _tmp2 = cross_tabulation(_tmp, classes)\n",
    "except Exception as e:\n",
    "    raise Exception(\"Your code probably does not accept textual class labels.\")\n",
    "assert _tmp2.shape == (6,len(np.unique(classes))+1), \"Wrong shape\"\n",
    "assert _tmp2.sum() == 4 * tfidf.shape[0], \"Not all elements\"\n",
    "assert (_tmp2[:,:-1].sum(axis=1) == _tmp2[:,-1]).all(), \"Sizes are bad\"\n",
    "assert (_tmp2[:-1].sum(axis=0) == _tmp2[-1]).all(), \"Sizes are bad\"\n",
    "del _tmp, _tmp2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1ef0462",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "61574652784f932e46e3e238120f4e6c",
     "grade": false,
     "grade_id": "cell-ed6cec5129fba54c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Implement a function to compute the pair counts from the cross-tabulation matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "id": "dcb3fdd2",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "fb963639c4d8f474ff79bb976e1975a7",
     "grade": false,
     "grade_id": "cell-b2c638c196f00570",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from math import comb\n",
    "def pair_count(crosstab):\n",
    "    \"\"\"Compute the pair count matrix from the cross-tabulation matrix.\"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    data = crosstab[:-1, :-1]\n",
    "    pairs_data = np.full((data.shape[0]+1,data.shape[1]+1), int(0))\n",
    "    \n",
    "    for i in range(len(data)):\n",
    "        for j in range(len(data[i])):\n",
    "            pairs_data[i][j] = comb(data[i][j],2)\n",
    "  \n",
    "    pairs_clusters = 0\n",
    "    for i in range(data.shape[0]):\n",
    "        pairs_data[i,-1] = comb(np.sum(data[i]),2)\n",
    "    \n",
    "    for i in range(len(crosstab[-1])):\n",
    "        pairs_data[-1,i] = comb(crosstab[-1,i],2) \n",
    "    return pairs_data   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "id": "9a582c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pair_count_mat(crosstab):\n",
    "    \"\"\"Compute the pair count matrix from the cross-tabulation matrix.\"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    data = crosstab[:-1, :-1]\n",
    "    pairs_data = np.full((data.shape[0],data.shape[1]), int(0))\n",
    "    \n",
    "    for i in range(len(data)):\n",
    "        for j in range(len(data[i])):\n",
    "            pairs_data[i][j] = comb(data[i][j],2)\n",
    "    true_positive = pairs_data.sum()\n",
    "    \n",
    "    pairs_clusters = 0\n",
    "    for i in range(data.shape[0]):\n",
    "        pairs_clusters = pairs_clusters + comb(np.sum(pairs_data[i]),2)\n",
    "    false_positive = pairs_clusters - true_positive\n",
    "    \n",
    "    last_row = crosstab[-1,:]\n",
    "    pairs_class = 0\n",
    "    for i in range(len(last_row)-1):\n",
    "        pairs_class = pairs_class + comb(last_row[i],2)\n",
    "    false_negative = pairs_class - true_positive\n",
    "    \n",
    "    true_negative = comb(crosstab[-1,-1],2) - true_positive - false_positive - false_negative\n",
    "    \n",
    "    pair_count_mat = np.full((2,2),int(0))\n",
    "    pair_count_mat[0,0], pair_count_mat[0,1] = true_positive, false_positive\n",
    "    pair_count_mat[1,0], pair_count_mat[1,1] = false_negative, true_negative\n",
    "    \n",
    "    return pair_count_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "id": "063846ac",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bc588c1a5ba95ffce6aeb7cd0e0fc21d",
     "grade": true,
     "grade_id": "cell-bc3e6b835f798750",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "### Automatic tests\n",
    "_, _tmp, _ = sphericalkmeans(tfidf, tfidf[:5], 1)\n",
    "_tmp2 = pair_count(cross_tabulation(_tmp, np.ones(tfidf.shape[0])))\n",
    "assert isinstance(_tmp2, np.ndarray), \"Must be an array\"\n",
    "assert np.issubdtype(_tmp2.dtype, np.integer), \"Must be an integer array\"\n",
    "if _tmp2.shape == (2,6): print(\"Use first parameter as first index.\")\n",
    "assert _tmp2.shape == (6,2), \"Wrong shape\"\n",
    "assert (_tmp2[:,:-1].sum(axis=1) == _tmp2[:,-1]).all(), \"Wrong result\"\n",
    "assert not (_tmp2[:-1].sum(axis=0) == _tmp2[-1]).all(), \"Wrong result\"\n",
    "_tmp2 = cross_tabulation(_tmp, _tmp)\n",
    "assert _tmp2.shape == (6,6), \"Wrong shape\"\n",
    "assert (_tmp2[:,:-1].sum(axis=1) == _tmp2[:,-1]).all(), \"Wrong result\"\n",
    "assert (_tmp2[:-1].sum(axis=0) == _tmp2[-1]).all(), \"Wrong result\"\n",
    "del _tmp, _tmp2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cba7222",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "96d97b3ae2dda22083f4397084c8a890",
     "grade": false,
     "grade_id": "cell-762612b2921774f2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Compute the Rand Index\n",
    "\n",
    "First compute the Rand Index of two assignments. You must use above functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "id": "10fff8d3",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7e15e43600ccafae98c66eda22136b9e",
     "grade": false,
     "grade_id": "cell-7e0b2f3e32ed4a44",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def rand_index(clu, cla):\n",
    "    # YOUR CODE HERE\n",
    "    crosstab = cross_tabulation(clu, cla)\n",
    "    pairs_data = pair_count(crosstab)\n",
    "    print(pairs_data)\n",
    "    data = pairs_data[:-1, :-1]\n",
    "    true_positive = data.sum()\n",
    "    false_positive = np.sum(pairs_data[:,-1]) - pairs_data[-1,-1] - true_positive\n",
    "    false_negative = np.sum(pairs_data[-1]) - pairs_data[-1,-1] - true_positive\n",
    "    true_negative = pairs_data[-1,-1] - true_positive - false_positive - false_negative\n",
    "    index = (true_positive + true_negative) / pairs_data[-1,-1]\n",
    "    return index\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "id": "f8f5d30a",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a1fa2794d73a99cf97f39f3c3d01c18d",
     "grade": true,
     "grade_id": "cell-329195060373cb5d",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<MagicMock name='pair_count()' id='139704747577456'>\n",
      "[[   94395    38226     2701   224785  3528496    24090   378015      528\n",
      "    132870 16545628]\n",
      " [    9870     3828       36     8646   263175      276    42778       28\n",
      "     22366  1332528]\n",
      " [    2016      595        3    15400   112101        6    31626        6\n",
      "     14028   695610]\n",
      " [     946      153        0      946    59685       10     7750        3\n",
      "      1711   207690]\n",
      " [     990     1081       21     2415    67161      171    26335       10\n",
      "      7750   418155]\n",
      " [  265356   107880     4371   596778 10440165    36856  1565565     1378\n",
      "    582660 51262875]]\n"
     ]
    }
   ],
   "source": [
    "### Automatic tests\n",
    "_, _tmp, _ = sphericalkmeans(tfidf, tfidf[:5], 1)\n",
    "from unittest.mock import patch\n",
    "with patch('__main__.cross_tabulation') as mock_u1, patch('__main__.pair_count') as mock_u2, patch('sklearn.metrics.rand_score') as mock_sk:\n",
    "    rand_index(_tmp, classes)\n",
    "assert mock_u1.called, \"Use the cross_tabulation function!\"\n",
    "assert mock_u2.called, \"Use the pair_count function!\"\n",
    "assert not mock_sk.called, \"Use your own code, not sklearn.\"\n",
    "ri = rand_index(_tmp, classes)\n",
    "assert ri <= 1, \"RI must be at most 1.\"\n",
    "assert ri > 0, \"RI must be always larger than 0.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "id": "08f111c4",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7f5fe9ed8a961296a3ceeb59b860673e",
     "grade": true,
     "grade_id": "cell-da2e0fd36986dccb",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "### Automatic tests\n",
    "import sklearn.metrics\n",
    "assert abs(ri - sklearn.metrics.rand_score(_tmp, classes)) < 1e-7, \"Result should agree with sklearn\"\n",
    "del _tmp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92319b59",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0df0f63cbc331ec4aad41a3d78433d76",
     "grade": false,
     "grade_id": "cell-bcc8771e63a5c1fe",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Compute the Adjusted Rand Index\n",
    "\n",
    "Write a function to compute the adjusted Rand index of two assignments. You must use above `pair_count` and `cross_tabulation` functions.\n",
    "\n",
    "Beware of integer overflows when using the equation from the slides. To resolve the integer overflow, transform the equation such that it has the standard form $ARI = \\frac{RI-E[RI]}{M-E[RI]}$ where RI is the rand index, $E[RI]$ is the expected value of the rand index (you need to derive this from the ARI equation given on the slides, do *not* attempt to figure out this equation directly; this assignment only needs standad high school math), and \\(M\\) is the maximum possible value of the Rand index (a constant)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "id": "18672f27",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "20f29162a39e21e24bff3e5247f29408",
     "grade": false,
     "grade_id": "cell-3c54c5708be33b13",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def adjusted_rand_index(clu, cla):\n",
    "    # YOUR CODE HERE\n",
    "    crosstab = cross_tabulation(clu, cla)\n",
    "    pairs_data = pair_count(crosstab)\n",
    "    data = pairs_data[:-1, :-1]\n",
    "    \n",
    "    true_positive = data.sum()\n",
    "    false_positive = np.sum(pairs_data[:,-1]) - pairs_data[-1,-1] - true_positive\n",
    "    false_negative = np.sum(pairs_data[-1]) - pairs_data[-1,-1] - true_positive\n",
    "    true_negative = pairs_data[-1,-1] - true_positive - false_positive - false_negative\n",
    "    \n",
    "    # array to resolve overflow error\n",
    "    v1_1 = int(true_positive+false_positive)\n",
    "    v1_2 = int(true_positive+false_negative)\n",
    "    v1 = int(v1_1*v1_2)\n",
    "    v2_1= int(false_negative+true_negative)\n",
    "    v2_2 = int(false_positive+true_negative)\n",
    "    v2 = int(v2_1 * v2_2)\n",
    "    expected_index = int(v1+v2)\n",
    "    index = int((true_positive + true_negative) * pairs_data[-1,-1])\n",
    "    optimal = np.power(pairs_data[-1,-1],2).astype(int)\n",
    "    \n",
    "    adj_index = (index - expected_index)/(optimal-expected_index)\n",
    "    return adj_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "id": "b7101979",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ef6cb334f895752bf7101fcaa1f83929",
     "grade": true,
     "grade_id": "cell-79f515ab2372b0b6",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "### Automatic tests\n",
    "_, _tmp, _ = sphericalkmeans(tfidf, tfidf[:5], 1)\n",
    "from unittest.mock import patch\n",
    "with patch('__main__.cross_tabulation') as mock_u1, patch('__main__.pair_count') as mock_u2, patch('sklearn.metrics.adjusted_rand_score') as mock_sk, patch('sklearn.metrics.rand_score') as mock_sk2:\n",
    "    adjusted_rand_index(_tmp, classes)\n",
    "assert mock_u1.called, \"Use the cross_tabulation function!\"\n",
    "assert mock_u2.called, \"Use the pair_count function!\"\n",
    "assert not mock_sk.called, \"Use your own code, not sklearn.\"\n",
    "assert not mock_sk2.called, \"Use your own code, not sklearn.\"\n",
    "ari = adjusted_rand_index(_tmp, classes)\n",
    "assert ari <= 1, \"ARI must be at most 1\"\n",
    "assert ari > 0, \"This clustering must score better than random.\"\n",
    "del _tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "id": "82bc4b82",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d986b76415be200de5452c5f322e4ff4",
     "grade": true,
     "grade_id": "cell-1113a5c4487f666f",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### Automatic tests\n",
    "_, _tmp, _ = sphericalkmeans(tfidf, tfidf[:5], 1)\n",
    "ari = adjusted_rand_index(_tmp, classes)\n",
    "import sklearn.metrics\n",
    "assert abs(ari - sklearn.metrics.adjusted_rand_score(_tmp, classes)) < 1e-7, \"Result should agree with sklearn\"\n",
    "del _tmp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bb782b2",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "49b825fac051ea351dc18b699e95dd15",
     "grade": false,
     "grade_id": "cell-0ef157590183b75b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Compute the Normalized Mutual Information\n",
    "\n",
    "Write a function to compute the Normalized Mutual Information (with arithmetic averaging) of two assignments.\n",
    "You must use above `pair_count` and `cross_tabulation` functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "id": "c90e3818",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "05543937f6c1edf33e4463e24a216453",
     "grade": false,
     "grade_id": "cell-5b724c2aa3e72f00",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from math import log2\n",
    "def normalized_mutual_information(clu, cla):\n",
    "    # YOUR CODE HERE\n",
    "    crosstab = cross_tabulation(clu, cla)\n",
    "    pairs_data = pair_count(crosstab)\n",
    "    N = crosstab[-1,-1]\n",
    "    information = 0\n",
    "    entropy1 = 0\n",
    "    entropy2 = 0\n",
    "    \n",
    "    \n",
    "    \n",
    "    for i in range(len(crosstab)-1):\n",
    "        for j in range(len(crosstab[i])-1):\n",
    "            val = (N*crosstab[i][j])/(crosstab[i,-1]*crosstab[-1,j])\n",
    "            if val>0:\n",
    "                information = information + ((crosstab[i][j]/N)*(np.log(val)))\n",
    "    arr = crosstab[:,-1]\n",
    "    for i in range(len(arr)-1):\n",
    "        entropy1 = entropy1 + -(arr[i]/N)*(np.log(arr[i]/N)) \n",
    "    \n",
    "    arr = crosstab[-1]\n",
    "    for i in range(len(arr)-1):\n",
    "        entropy2 = entropy2 + -(arr[i]/N)*(np.log(arr[i]/N)) \n",
    "    \n",
    "    nmi = (2*information)/(entropy1+entropy2)\n",
    "    return nmi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "id": "58d111eb",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "13daec252ab272e117490e5fa4dc915a",
     "grade": true,
     "grade_id": "cell-919137944c4c0c89",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "### Automatic tests\n",
    "_, _tmp, _ = sphericalkmeans(tfidf, tfidf[:5], 1)\n",
    "from unittest.mock import patch\n",
    "with patch('sklearn.metrics.normalized_mutual_info_score', side_effect=Exception(\"Use your own code, not skelarn\")) as mock_sk1,  patch('sklearn.metrics.mutual_info_score', side_effect=Exception(\"Use your own code, not skelarn\")) as mock_sk2:\n",
    "    normalized_mutual_information(_tmp, classes)\n",
    "nmi = normalized_mutual_information(_tmp, classes)\n",
    "assert nmi <= 1, \"NMI must be at most 1\"\n",
    "assert nmi > 0, \"This clustering must score better than random.\"\n",
    "del _tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "id": "1d0c5169",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8d6e20382134c8e8995838384b312ed8",
     "grade": true,
     "grade_id": "cell-8987caee47e63f78",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "### Automatic tests\n",
    "_, _tmp, _ = sphericalkmeans(tfidf, tfidf[:5], 1)\n",
    "nmi = normalized_mutual_information(_tmp, classes)\n",
    "import sklearn.metrics\n",
    "assert abs(nmi - sklearn.metrics.normalized_mutual_info_score(_tmp, classes)) < 1e-10, \"Result should agree with sklearn\"\n",
    "del _tmp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd0da594",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "003ec7db49b44ca56647ef6dc67ea557",
     "grade": false,
     "grade_id": "cell-528f9f2cca4e7e38",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Finding the best clustering\n",
    "\n",
    "for $k=1..15$, and a fixed random seed of 0, find the best spherical k-means clustering by NMI compared to the classes stored in `classes` above (note that this will not generally be possible, as our data usually will not be labeled)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "id": "c5153913",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9a113c685be46afb769d2e462c856bc3",
     "grade": false,
     "grade_id": "cell-c608e9355ae7e4b8",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[0;32mIn [495]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m bestassignment \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;66;03m# Store the best assignment here\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# YOUR CODE HERE\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m()\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe best k is\u001b[39m\u001b[38;5;124m\"\u001b[39m, bestk, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscoring\u001b[39m\u001b[38;5;124m\"\u001b[39m, bestnmi)\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "bestk = None # Store best k here\n",
    "bestnmi = None # Store the best NMI here\n",
    "bestassignment = None # Store the best assignment here\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "print(\"The best k is\", bestk, \"scoring\", bestnmi)\n",
    "# Hint: it will *not* score very good. The classes are not clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "877f436a",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bfcd004607f35e14c0aac8c07633d0af",
     "grade": true,
     "grade_id": "cell-75f2a8a9685b1144",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "### Automatic tests\n",
    "assert bestk > 0 and bestk <= 15\n",
    "assert bestk == len(np.unique(bestassignment)), \"Inconsistent result\"\n",
    "assert abs(bestnmi-sklearn.metrics.normalized_mutual_info_score(bestassignment, classes)) < 1e-7, \"Inconsistent result\"\n",
    "assert all(bestassignment == sphericalkmeans(tfidf, initial_centers(tfidf, bestk, 0))[1]), \"Inconsistent result\"\n",
    "assert bestk > 2, \"There should be something better\"\n",
    "assert bestk < 15, \"There should be something better\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "554575ff",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e80cdb14b5240d961a2ce03691672d2e",
     "grade": true,
     "grade_id": "cell-e93e6fa091666397",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "### Additional Automatic tests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b09502e4",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5430abf1c9b3a3483a4da4c29064687e",
     "grade": false,
     "grade_id": "cell-bfe6416f6601f045",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Explore the result\n",
    "\n",
    "Explore the clustering result, by comparing it to the original classes.\n",
    "\n",
    "For each cluster, return the cluster label, the three top classes, and the percentages of the clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3836bfa5",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5449ee738333b99dddd5453d1cd707d5",
     "grade": false,
     "grade_id": "cell-63587c44768ee69f",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def top_classes(clu, cla):\n",
    "    \"\"\"For each cluster, give the top three classes and their share of the data each.\"\"\"\n",
    "    # For each cluster, call yield label, *top3, *shares to return a 7-tuple.\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2390fec",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2d3f61b95b0e9a5da01b5596edfe9629",
     "grade": true,
     "grade_id": "cell-2536f746075d1e01",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "### Automatic tests\n",
    "_tmp = top_classes(classes, classes)\n",
    "import types\n",
    "assert isinstance(_tmp, types.GeneratorType), \"You did not use `yield`.\"\n",
    "_tmp = list(_tmp)\n",
    "assert len(_tmp) == len(np.unique(classes)), \"Wrong number of results\"\n",
    "for row in _tmp:\n",
    "    assert len(row) == 7, \"Not a 7-tuple\"\n",
    "    assert row[0] in classes, \"Not a label\"\n",
    "    assert row[0] == row[1], \"Incorrect result\"\n",
    "    assert row[4:] == (1.,0.,0.), \"Incorrect result\"\n",
    "del _tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a1c6e71",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7fd5e5fe14192e67f67d0611413ea90a",
     "grade": true,
     "grade_id": "cell-31342b8247fac176",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "### Automatic tests\n",
    "_tmp = top_classes(bestassignment, classes)\n",
    "import types\n",
    "assert isinstance(_tmp, types.GeneratorType), \"You did not use `yield`.\"\n",
    "_tmp = list(_tmp)\n",
    "assert len(_tmp) == bestk, \"Wrong number of results\"\n",
    "for row in _tmp:\n",
    "    assert len(row) == 7, \"Not a 7-tuple\"\n",
    "    assert row[1] in classes, \"Not a label\"\n",
    "# Additional hidden tests\n",
    "del _tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4129522",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e1e24764e369997816b5c2c5e39a049b",
     "grade": false,
     "grade_id": "cell-2773fe306b0aa792",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Explore your best clustering!\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
