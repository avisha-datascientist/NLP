{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6da7fd2a",
   "metadata": {},
   "source": [
    "Before you turn this problem in, make sure everything runs as expected. First, **restart the kernel** (in the menubar, select Kernel$\\rightarrow$Restart) and then **run all cells** (in the menubar, select Cell$\\rightarrow$Run All) to avoid typical problems with Jupyter notebooks. **Unfortunately, this does not work with Chrome right now, you will also need to reload the tab in Chrome afterwards**.\n",
    "\n",
    "Make sure you fill in any place that says `YOUR CODE HERE` or \"YOUR ANSWER HERE\". Please put your name here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9e70a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME = \"AVISHA ANILKUMAR BHIRYANI\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c160ff0",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccc15fc1",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c0dab411feddd75be4b23091cf4d0fa8",
     "grade": false,
     "grade_id": "cell-dddd9b472cdda421",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Latent Semantic Indexing\n",
    "\n",
    "First we will implement latent semantic indexing (LSI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "43686fed",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6dd047a5f2cf5fdc2ca134bcc7fecd40",
     "grade": false,
     "grade_id": "cell-cf0a1f8d45f50016",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "### Load the input data - do not modify\n",
    "import json, gzip, numpy as np\n",
    "raw = json.load(gzip.open(\"/data/simpsonswiki.json.gz\", \"rt\", encoding=\"utf-8\"))\n",
    "titles, texts, classes = [x[\"title\"] for x in raw], [x[\"text\"] for x in raw], [x[\"c\"] for x in raw]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a878ace3",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0265525e0f001028656b86682e2c714c",
     "grade": false,
     "grade_id": "cell-dafc634f8c46b474",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "### Vectorize the text - do not modify\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "vect = TfidfVectorizer(stop_words=\"english\", sublinear_tf=True, smooth_idf=False, min_df=5)\n",
    "vect.fit(texts)\n",
    "vect.idf_ -= 1\n",
    "idf = vect.idf_\n",
    "tfidf = vect.transform(texts)\n",
    "vocabulary = vect.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6841eb00",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7911b9f7fd7af796b2b2e6c41c625839",
     "grade": false,
     "grade_id": "cell-fbcd1050af6399c4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Implement LSI\n",
    "\n",
    "Implement Latent Semantic Indexing. Do **not** use regular SVD, but instead use truncated SVD from sklearn. (Do not attempt to implement Truncated SVD yourself, use the library here.) Return weights how well the factors explain the topics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a1087ff8",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3684f36adea2ec55fd6fb17d909681b3",
     "grade": false,
     "grade_id": "cell-8eb426fb1c1146b0",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Implement LSI here\n",
    "def lsi(tfidf, k):\n",
    "    \"\"\"Latent Semantic Indexing. Return the factors, document assignment, and factor weights\"\"\"\n",
    "    from sklearn.decomposition import TruncatedSVD\n",
    "    # YOUR CODE HERE\n",
    "    svd = TruncatedSVD(n_components=k)\n",
    "    svd.fit(tfidf)\n",
    "    #V matrix - column wise\n",
    "    factors = svd.components_\n",
    "    #U matrix - row vise\n",
    "    assignment = svd.transform(tfidf)\n",
    "    weights = svd.explained_variance_\n",
    "    return factors, assignment, weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1c7747a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 14153)\n",
      "(10126, 2)\n"
     ]
    }
   ],
   "source": [
    "_tmp = lsi(tfidf, 2)\n",
    "print(_tmp[0].shape)\n",
    "print(_tmp[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "32c3c657",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "969bd1e651ce6ee4dd9e120e9fbf631f",
     "grade": true,
     "grade_id": "cell-30066761f95116e7",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "### Automatic tests. You do not need to understand or modify this code.\n",
    "_tmp = lsi(tfidf, 2)\n",
    "assert len(_tmp) == 3, \"Incomplete result\"\n",
    "assert _tmp[0].shape == (2, tfidf.shape[1]), \"Factor shape is not correct.\"\n",
    "assert _tmp[1].shape == (tfidf.shape[0], 2), \"Assignment shape is not correct.\"\n",
    "del _tmp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df4af627",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "563e69e91ed535af91bc414ac2ea0bcb",
     "grade": false,
     "grade_id": "cell-f50d41a9220315d1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Explore your result\n",
    "\n",
    "Explore the result: write a function to determine the most important words for each factor, and the most relevant documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "9dcf971e",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8d81e82f2aaf8dedf2e57743c005ffe4",
     "grade": false,
     "grade_id": "cell-c3a23922942e74ed",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def most_important(vocabulary, factor, k=10):\n",
    "    \"\"\"Most important words for each factor\"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    dict_words = {}\n",
    "    i = 0\n",
    "    for key in vocabulary:\n",
    "        dict_words[key] = factor[i]\n",
    "        i = i+1\n",
    "    sorted_words = dict(sorted(dict_words.items(), key=lambda item: item[1], reverse=True))\n",
    "    arr = [each for each in list(sorted_words)[:k]]\n",
    "    return arr\n",
    "        \n",
    "def most_relevant(assignment, k=5):\n",
    "    \"\"\"Most relevant documents for each factor (return document indexes)\"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    arr = []\n",
    "    dict_docs = {}\n",
    "    for i in range(0,len(assignment)):\n",
    "        dict_docs[i] = assignment[i]\n",
    "        i = i+1\n",
    "    sorted_docs = dict(sorted(dict_docs.items(), key=lambda item: item[1], reverse=True))\n",
    "    arr= [each for each in list(sorted_docs)[:k]]\n",
    "    return arr\n",
    "\n",
    "def explain(vocabulary, titles, classes, factors, assignment, weights=None):\n",
    "    \"\"\"Print an explanation for each factor.\n",
    "       If weights is None, use the relative share of the assignment weights.\n",
    "       Print the ARI when assigning each document to its maximum only.\"\"\"\n",
    "    from sklearn.metrics import adjusted_rand_score\n",
    "    # YOUR CODE HERE\n",
    "    if weights is not None:\n",
    "        total_factors = factors.shape[0]\n",
    "        for i in range(0,total_factors):\n",
    "            important_words = most_important(vocabulary, factors[i])\n",
    "            important_docs = most_relevant(assignment[:i])\n",
    "            print(i)\n",
    "            print(important_docs)\n",
    "            print(important_words)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "454334f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "[]\n",
      "['couch', 'simpson', 'homer', 'bart', 'lisa', 'marge', 'gag', 'family', 'song', 'maggie']\n",
      "1\n",
      "[0]\n",
      "['couch', 'gag', 'simpson', 'plot', 'maggie', 'appearances', 'character', 'season', 'family', 'sit']\n"
     ]
    }
   ],
   "source": [
    "explain(vocabulary, titles, classes, *_tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "c36f67c8",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "940359a2f771cf68c33fdf35328e3fd9",
     "grade": true,
     "grade_id": "cell-53f1929d10c5494e",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "### Automatic tests. You do not need to understand or modify this code.\n",
    "_tmp = lsi(tfidf, 2)\n",
    "assert len(most_important(vocabulary, _tmp[0][0], 42)) == 42, \"Wrong number of most important words\"\n",
    "for x in most_important(vocabulary, _tmp[0][0]): assert isinstance(x, str), \"Most important words are not words\"\n",
    "assert len(most_relevant(_tmp[1][:,0], 42)) == 42, \"Wrong number of relevant results.\"\n",
    "from unittest.mock import patch\n",
    "with patch('__main__.most_important') as mock_1, patch('__main__.most_relevant') as mock_2, patch('__main__.print') as mock_3:\n",
    "    explain(vocabulary, titles, classes, *_tmp)\n",
    "    assert mock_1.called, \"You did not use most_important\"\n",
    "    assert mock_2.called, \"You did not use most_central\"\n",
    "    assert mock_3.called, \"You did not print\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "8016d412",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f04f83f48c428d2a9c1f7d42f62170c4",
     "grade": false,
     "grade_id": "cell-92ab6cc019fb7fbd",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "[]\n",
      "['couch', 'simpson', 'homer', 'bart', 'lisa', 'marge', 'gag', 'family', 'song', 'maggie']\n",
      "1\n",
      "[0]\n",
      "['couch', 'gag', 'simpson', 'plot', 'maggie', 'appearances', 'character', 'season', 'family', 'sit']\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [125]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Explore your result. These should mostly be meaningful topics!\u001b[39;00m\n\u001b[1;32m      2\u001b[0m lsi_factors, lsi_assignment, lsi_weights \u001b[38;5;241m=\u001b[39m lsi(tfidf, \u001b[38;5;241m6\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m \u001b[43mexplain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvocabulary\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtitles\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclasses\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlsi_factors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlsi_assignment\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlsi_weights\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [122]\u001b[0m, in \u001b[0;36mexplain\u001b[0;34m(vocabulary, titles, classes, factors, assignment, weights)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m,total_factors):\n\u001b[1;32m     34\u001b[0m     important_words \u001b[38;5;241m=\u001b[39m most_important(vocabulary, factors[i])\n\u001b[0;32m---> 35\u001b[0m     important_docs \u001b[38;5;241m=\u001b[39m \u001b[43mmost_relevant\u001b[49m\u001b[43m(\u001b[49m\u001b[43massignment\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     36\u001b[0m     \u001b[38;5;28mprint\u001b[39m(i)\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;28mprint\u001b[39m(important_docs)\n",
      "Input \u001b[0;32mIn [122]\u001b[0m, in \u001b[0;36mmost_relevant\u001b[0;34m(assignment, k)\u001b[0m\n\u001b[1;32m     19\u001b[0m     dict_docs[i] \u001b[38;5;241m=\u001b[39m assignment[i]\n\u001b[1;32m     20\u001b[0m     i \u001b[38;5;241m=\u001b[39m i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[0;32m---> 21\u001b[0m sorted_docs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(\u001b[38;5;28;43msorted\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdict_docs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mitem\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mitem\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreverse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m)\n\u001b[1;32m     22\u001b[0m arr\u001b[38;5;241m=\u001b[39m [each \u001b[38;5;28;01mfor\u001b[39;00m each \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(sorted_docs)[:k]]\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m arr\n",
      "\u001b[0;31mValueError\u001b[0m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"
     ]
    }
   ],
   "source": [
    "# Explore your result. These should mostly be meaningful topics!\n",
    "lsi_factors, lsi_assignment, lsi_weights = lsi(tfidf, 6)\n",
    "explain(vocabulary, titles, classes, lsi_factors, lsi_assignment, lsi_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "7c801c7f",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "31e4e93d8c9e9ae7b2adf035f3f049a2",
     "grade": true,
     "grade_id": "cell-cf8643ed125237fa",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "### This cell contains additional tests. You do not need to modify this cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa673279",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
