{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "64c6a8b1",
   "metadata": {},
   "source": [
    "Before you turn this problem in, make sure everything runs as expected. First, **restart the kernel** (in the menubar, select Kernel$\\rightarrow$Restart) and then **run all cells** (in the menubar, select Cell$\\rightarrow$Run All) to avoid typical problems with Jupyter notebooks. **Unfortunately, this does not work with Chrome right now, you will also need to reload the tab in Chrome afterwards**.\n",
    "\n",
    "Make sure you fill in any place that says `YOUR CODE HERE` or \"YOUR ANSWER HERE\". Please put your name here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f62fb32",
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME = \"AVISHA ANILKUMAR BHIRYANI\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be4eeb6f",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccc15fc1",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9ced10babba5dd187ba80f65774dd05f",
     "grade": false,
     "grade_id": "cell-dddd9b472cdda421",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Probabilistic Latent Semantic Indexing\n",
    "\n",
    "Now we will implement latent semantic indexing (LSI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "43686fed",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6dd047a5f2cf5fdc2ca134bcc7fecd40",
     "grade": false,
     "grade_id": "cell-cf0a1f8d45f50016",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "### Load the input data - do not modify\n",
    "import json, gzip, numpy as np\n",
    "raw = json.load(gzip.open(\"/data/simpsonswiki.json.gz\", \"rt\", encoding=\"utf-8\"))\n",
    "titles, texts, classes = [x[\"title\"] for x in raw], [x[\"text\"] for x in raw], [x[\"c\"] for x in raw]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7198d845",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "264d6f477689c6087be9840a47f0289e",
     "grade": true,
     "grade_id": "cell-efe7fecd64a3b68c",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "### This cell reduces the data set size for the autograder tests - do not modify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a878ace3",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7c5f701671ffe89035fb4e56423452cb",
     "grade": false,
     "grade_id": "cell-dafc634f8c46b474",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "### Vectorize the text - do not modify\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cvect = CountVectorizer(stop_words=\"english\", min_df=5)\n",
    "counts = cvect.fit_transform(texts)\n",
    "vocabulary = cvect.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df4af627",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c0a9ec6fdd6e31f5bd8c6169e2a83a0f",
     "grade": false,
     "grade_id": "cell-f50d41a9220315d1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Explore your result\n",
    "\n",
    "Explore the result: write a function to determine the most important words for each factor, and the most relevant documents.\n",
    "\n",
    "**COPY your code from the first file here** (this is a rare case where copying is okay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9dcf971e",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8d81e82f2aaf8dedf2e57743c005ffe4",
     "grade": false,
     "grade_id": "cell-c3a23922942e74ed",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def most_important(vocabulary, factor, k=10):\n",
    "    \"\"\"Most important words for each factor\"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    dict_words = {}\n",
    "    i = 0\n",
    "    for key in vocabulary:\n",
    "        dict_words[key] = factor[i]\n",
    "        i = i+1\n",
    "    sorted_words = dict(sorted(dict_words.items(), key=lambda item: item[1], reverse=True))\n",
    "    arr = [each for each in list(sorted_words)[:k]]\n",
    "    return arr\n",
    "\n",
    "def most_relevant(assignment, k=5):\n",
    "    \"\"\"Most relevant documents for each factor (return document indexes)\"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    arr = []\n",
    "    dict_docs = {}\n",
    "    for i in range(0,len(assignment)):\n",
    "        dict_docs[i] = assignment[i]\n",
    "        i = i+1\n",
    "    sorted_docs = dict(sorted(dict_docs.items(), key=lambda item: item[1], reverse=True))\n",
    "    arr= [each for each in list(sorted_docs)[:k]]\n",
    "    return arr\n",
    "\n",
    "def explain(vocabulary, titles, classes, factors, assignment, weights=None):\n",
    "    \"\"\"Print an explanation for each factor.\n",
    "       If weights is None, use the relative share of the assignment weights.\n",
    "       Print the ARI when assigning each document to its maximum only.\"\"\"\n",
    "    from sklearn.metrics import adjusted_rand_score\n",
    "    # YOUR CODE HERE\n",
    "    if weights is not None:\n",
    "        total_factors = factors.shape[0]\n",
    "        for i in range(0,total_factors):\n",
    "            important_words = most_important(vocabulary, factors[i])\n",
    "            important_docs = most_relevant(assignment[:i])\n",
    "            print(i)\n",
    "            print(important_docs)\n",
    "            print(important_words)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff4f0ef9",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "fab800476249bd37078f2d8bf89667f2",
     "grade": false,
     "grade_id": "cell-00e0e4e0fa7cf5df",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Implement probabilistic Latent Semantic Indexing\n",
    "\n",
    "Implement pLSI using the non-negative matrix factorization function of sklearn. Make sure to choose appropriate parameters to use KL divergence -- it is not sufficient to use defaults!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a72eead9",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "63665feee65836d1e81f43397ef49174",
     "grade": false,
     "grade_id": "cell-6a46ed0ac1bb4018",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Implement pLSI here using NMF\n",
    "def plsi(counts, k):\n",
    "    \"\"\"Probabilistic Latent Semantic Indexing. Return the factors and document assignment\"\"\"\n",
    "    from sklearn.decomposition import NMF\n",
    "    # YOUR CODE HERE\n",
    "    model = NMF(n_components=k, solver = 'mu', beta_loss='kullback-leibler')\n",
    "    model_fit = model.fit(counts)\n",
    "    assignment = model_fit.transform(counts)\n",
    "    factors = model.components_\n",
    "    return factors, assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4726edbb",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "acf5ab3248916a0a99b32b35dbf3f632",
     "grade": true,
     "grade_id": "cell-8493a4259f377dbe",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/sklearn/decomposition/_nmf.py:289: FutureWarning: The 'init' value, when 'init=None' and n_components is less than n_samples and n_features, will be changed from 'nndsvd' to 'nndsvda' in 1.1 (renaming of 0.26).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "### Automatic tests. You do not need to understand or modify this code.\n",
    "from unittest.mock import patch\n",
    "with patch('gensim.models.lsimodel.LsiModel') as mock_2:\n",
    "    _tmp = plsi(counts, 2)\n",
    "    assert len(_tmp) == 2, \"Incomplete result\"\n",
    "    assert _tmp[0].shape == (2, counts.shape[1]), \"Factor shape is not correct.\"\n",
    "    assert _tmp[1].shape == (counts.shape[0], 2), \"Assignment shape is not correct.\"\n",
    "    assert not mock_2.called, \"You were supposed to use sklearn here, not gensim.\"\n",
    "del _tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1f0a08ce",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e020359de984836220e0684f52fad3e7",
     "grade": true,
     "grade_id": "cell-0586d9e76933c1bb",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "### This cell contains additional tests. You do not need to modify this cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "be9d3543",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "83ec05ef5a096dad41236ded4cd68f1d",
     "grade": false,
     "grade_id": "cell-8b2811a2d3403995",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/sklearn/decomposition/_nmf.py:289: FutureWarning: The 'init' value, when 'init=None' and n_components is less than n_samples and n_features, will be changed from 'nndsvd' to 'nndsvda' in 1.1 (renaming of 0.26).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Explore your result. These must be meaningful topics!\n",
    "plsi_factors, plsi_assignment = plsi(counts, 6)\n",
    "explain(vocabulary, titles, classes, plsi_factors, plsi_assignment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c75563fa",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "33abcbaa84ed83cca750145aa20b9cca",
     "grade": true,
     "grade_id": "cell-cd45412a261736bb",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "### This cell contains additional tests. You do not need to modify this cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3584fae1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
